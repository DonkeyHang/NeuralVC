{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import itertools\n",
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import HParams\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import (\n",
    "  TextAudioSpeakerLoader,\n",
    "  TextAudioSpeakerCollate,\n",
    "  DistributedBucketSampler\n",
    ")\n",
    "from models import (\n",
    "  HuBERT_NeuralDec_VITS,\n",
    "  MultiPeriodDiscriminator,\n",
    ")\n",
    "from losses import (\n",
    "  generator_loss,\n",
    "  discriminator_loss,\n",
    "  feature_loss,\n",
    "  kl_loss\n",
    ")\n",
    "from mel_processing import mel_spectrogram_torch, spec_to_mel_torch\n",
    "from speaker_encoder.voice_encoder import SpeakerEncoder\n",
    "smodel = SpeakerEncoder('speaker_encoder/ckpt/pretrained_bak_5805000.pt')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "global_step = 0                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.config = \"./configs/hubert-neuraldec-vits.json\"\n",
    "        self.model = \"neuralvc-temp\"\n",
    "\n",
    "\n",
    "args = Parameters()\n",
    "\n",
    "def get_hparams(init=True):\n",
    "\n",
    "  model_dir = os.path.join(\"./logs\", args.model)\n",
    "\n",
    "  if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "  config_path = args.config\n",
    "  config_save_path = os.path.join(model_dir, \"config.json\")\n",
    "  if init:\n",
    "    with open(config_path, \"r\") as f:\n",
    "      data = f.read()\n",
    "    with open(config_save_path, \"w\") as f:\n",
    "      f.write(data)\n",
    "  else:\n",
    "    with open(config_save_path, \"r\") as f:\n",
    "      data = f.read()\n",
    "  config = json.loads(data)\n",
    "  \n",
    "  hparams = HParams(**config)\n",
    "  hparams.model_dir = model_dir\n",
    "  return hparams\n",
    "\n",
    "hps = get_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spk_loss(tgt, gen, batch_size):\n",
    "    loss = 0.0\n",
    "    for i in range(batch_size):\n",
    "        tgt_emb = smodel.embed_utterance(tgt[i][0])\n",
    "        gen_emb = smodel.embed_utterance(gen[i][0])\n",
    "\n",
    "        loss += F.l1_loss(torch.from_numpy(tgt_emb), torch.from_numpy(gen_emb))\n",
    "\n",
    "    return loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  \"\"\"Assume Single Node Multi GPUs Training Only\"\"\"\n",
    "  assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "  n_gpus = torch.cuda.device_count()\n",
    "  run(0,n_gpus, hps)\n",
    "\n",
    "def run(rank, n_gpus, hps):\n",
    "  global global_step\n",
    "  if rank == 0:\n",
    "    logger = utils.get_logger(hps.model_dir)\n",
    "    logger.info(hps)\n",
    "    utils.check_git_hash(hps.model_dir)\n",
    "    writer = SummaryWriter(log_dir=hps.model_dir)\n",
    "    writer_eval = SummaryWriter(log_dir=os.path.join(hps.model_dir, \"eval\"))\n",
    "\n",
    "  #dist.init_process_group(backend='nccl', init_method='env://', world_size=n_gpus, rank=rank)\n",
    "  torch.manual_seed(hps.train.seed)\n",
    "  torch.cuda.set_device(rank)\n",
    "\n",
    "  train_dataset = TextAudioSpeakerLoader(hps.data.training_files, hps)\n",
    "  train_sampler = DistributedBucketSampler(\n",
    "      train_dataset,\n",
    "      hps.train.batch_size,\n",
    "      [75,100,125,150,175,200,225,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1100,1200,1300,1400,1500,2000,3000,4000,5000],\n",
    "      num_replicas=n_gpus,\n",
    "      rank=rank,\n",
    "      shuffle=True)\n",
    "  collate_fn = TextAudioSpeakerCollate(hps)\n",
    "  train_loader = DataLoader(train_dataset, num_workers=0, shuffle=False, pin_memory=True,\n",
    "      collate_fn=collate_fn, batch_sampler=train_sampler)\n",
    "  if rank == 0:\n",
    "    eval_dataset = TextAudioSpeakerLoader(hps.data.validation_files, hps)\n",
    "    eval_loader = DataLoader(eval_dataset, num_workers=0, shuffle=True,\n",
    "        batch_size=hps.train.batch_size, pin_memory=False,\n",
    "        drop_last=False, collate_fn=collate_fn)\n",
    "\n",
    "  net_g = HuBERT_NeuralDec_VITS(\n",
    "      hps.data.filter_length // 2 + 1,\n",
    "      hps.train.segment_size // hps.data.hop_length,\n",
    "      **hps.model).cuda(rank)\n",
    "  net_d = MultiPeriodDiscriminator(hps.model.use_spectral_norm).cuda(rank)\n",
    "  optim_g = torch.optim.AdamW(\n",
    "      net_g.parameters(), \n",
    "      hps.train.learning_rate, \n",
    "      betas=hps.train.betas, \n",
    "      eps=hps.train.eps)\n",
    "  optim_d = torch.optim.AdamW(\n",
    "      net_d.parameters(),\n",
    "      hps.train.learning_rate, \n",
    "      betas=hps.train.betas, \n",
    "      eps=hps.train.eps)\n",
    "\n",
    "  try:\n",
    "    _, _, _, epoch_str = utils.load_checkpoint(utils.latest_checkpoint_path(hps.model_dir, \"G_*.pth\"), net_g, optim_g)\n",
    "    _, _, _, epoch_str = utils.load_checkpoint(utils.latest_checkpoint_path(hps.model_dir, \"D_*.pth\"), net_d, optim_d)\n",
    "    global_step = (epoch_str - 1) * len(train_loader)\n",
    "  except:\n",
    "    epoch_str = 1\n",
    "    global_step = 0\n",
    "\n",
    "  scheduler_g = torch.optim.lr_scheduler.ExponentialLR(optim_g, gamma=hps.train.lr_decay, last_epoch=epoch_str-2)\n",
    "  scheduler_d = torch.optim.lr_scheduler.ExponentialLR(optim_d, gamma=hps.train.lr_decay, last_epoch=epoch_str-2)\n",
    "\n",
    "  scaler = GradScaler(enabled=hps.train.fp16_run)\n",
    "\n",
    "  for epoch in range(epoch_str, hps.train.epochs + 1):\n",
    "    if rank==0:\n",
    "      train_and_evaluate(rank, epoch, hps, [net_g, net_d], [optim_g, optim_d], [scheduler_g, scheduler_d], scaler, [train_loader, eval_loader], logger, [writer, writer_eval])\n",
    "    else:\n",
    "      train_and_evaluate(rank, epoch, hps, [net_g, net_d], [optim_g, optim_d], [scheduler_g, scheduler_d], scaler, [train_loader, None], None, None)\n",
    "    scheduler_g.step()\n",
    "    scheduler_d.step()\n",
    "\n",
    "def train_and_evaluate(rank, epoch, hps, nets, optims, schedulers, scaler, loaders, logger, writers):\n",
    "  \n",
    "  net_g, net_d = nets\n",
    "  optim_g, optim_d = optims\n",
    "  scheduler_g, scheduler_d = schedulers\n",
    "  train_loader, eval_loader = loaders\n",
    "  if writers is not None:\n",
    "    writer, writer_eval = writers\n",
    "\n",
    "  train_loader.batch_sampler.set_epoch(epoch)\n",
    "  global global_step\n",
    "\n",
    "  net_g.train()\n",
    "  net_d.train()\n",
    "  for batch_idx, items in enumerate(train_loader):\n",
    "    if hps.model.use_spk:\n",
    "      c, spec, y, spk = items\n",
    "      g = spk.cuda(rank, non_blocking=True)\n",
    "    else:\n",
    "      c, spec, y = items\n",
    "      g = None\n",
    "    spec, y = spec.cuda(rank, non_blocking=True), y.cuda(rank, non_blocking=True)\n",
    "    c = c.cuda(rank, non_blocking=True)\n",
    "    # print(\"***\" + spec.shape)\n",
    "    mel = spec_to_mel_torch(\n",
    "          spec, \n",
    "          hps.data.filter_length, \n",
    "          hps.data.n_mel_channels, \n",
    "          hps.data.sampling_rate,\n",
    "          hps.data.mel_fmin, \n",
    "          hps.data.mel_fmax)\n",
    "    real_mel = mel_spectrogram_torch(\n",
    "          y.squeeze(1), \n",
    "          hps.data.filter_length, \n",
    "          hps.data.n_mel_channels, \n",
    "          hps.data.sampling_rate, \n",
    "          hps.data.hop_length, \n",
    "          hps.data.win_length, \n",
    "          hps.data.mel_fmin, \n",
    "          hps.data.mel_fmax\n",
    "      )\n",
    "    #print(torch.max(mel),torch.min(mel),torch.max(real_mel),torch.min(real_mel))\n",
    "    with autocast(enabled=hps.train.fp16_run):\n",
    "      y_hat, ids_slice, z_mask,\\\n",
    "      (z, z_p, m_p, logs_p, m_q, logs_q) = net_g(c, spec, g=g, mel=mel)\n",
    "      #print(torch.max(y),torch.min(y),torch.max(y_hat),torch.min(y_hat))\n",
    "      y_mel = commons.slice_segments(mel, ids_slice, hps.train.segment_size // hps.data.hop_length)\n",
    "      y_hat_mel = mel_spectrogram_torch(\n",
    "          y_hat.squeeze(1), \n",
    "          hps.data.filter_length, \n",
    "          hps.data.n_mel_channels, \n",
    "          hps.data.sampling_rate, \n",
    "          hps.data.hop_length, \n",
    "          hps.data.win_length, \n",
    "          hps.data.mel_fmin, \n",
    "          hps.data.mel_fmax\n",
    "      )\n",
    "      y = commons.slice_segments(y, ids_slice * hps.data.hop_length, hps.train.segment_size) # slice \n",
    "\n",
    "      # Discriminator\n",
    "      y_d_hat_r, y_d_hat_g, _, _ = net_d(y, y_hat.detach())\n",
    "      with autocast(enabled=False):\n",
    "        loss_disc, losses_disc_r, losses_disc_g = discriminator_loss(y_d_hat_r, y_d_hat_g)\n",
    "        loss_disc_all = loss_disc\n",
    "    optim_d.zero_grad()\n",
    "    scaler.scale(loss_disc_all).backward()\n",
    "    scaler.unscale_(optim_d)\n",
    "    grad_norm_d = commons.clip_grad_value_(net_d.parameters(), None)\n",
    "    scaler.step(optim_d)\n",
    "    with autocast(enabled=hps.train.fp16_run):\n",
    "      # Generator\n",
    "      y_d_hat_r, y_d_hat_g, fmap_r, fmap_g = net_d(y, y_hat)\n",
    "      with autocast(enabled=False):\n",
    "        loss_kl = kl_loss(z_p, logs_q, m_p, logs_p, z_mask) * hps.train.c_kl\n",
    "        loss_mel = F.l1_loss(y_hat_mel, y_mel) * hps.train.c_mel\n",
    "        loss_fm = feature_loss(fmap_r, fmap_g)\n",
    "        loss_gen, losses_gen = generator_loss(y_d_hat_g)\n",
    "        loss_spk = spk_loss(y.detach().cpu().numpy(), y_hat.detach().cpu().numpy(), hps.train.batch_size)\n",
    "        loss_gen_all = loss_gen + loss_fm + loss_mel + loss_kl + loss_spk\n",
    "    optim_g.zero_grad()\n",
    "    scaler.scale(loss_gen_all).backward()\n",
    "    scaler.unscale_(optim_g)\n",
    "    grad_norm_g = commons.clip_grad_value_(net_g.parameters(), None)\n",
    "    scaler.step(optim_g)\n",
    "    scaler.update()\n",
    "\n",
    "    if rank==0:\n",
    "      if global_step % hps.train.log_interval == 0:\n",
    "        lr = optim_g.param_groups[0]['lr']\n",
    "        losses = [loss_disc, loss_gen, loss_fm, loss_mel]\n",
    "        logger.info('Train Epoch: {} [{:.0f}%]'.format(\n",
    "          epoch,\n",
    "          100. * batch_idx / len(train_loader)))\n",
    "        logger.info([x.item() for x in losses] + [global_step, lr])\n",
    "        \n",
    "        scalar_dict = {\"loss/g/total\": loss_gen_all, \"loss/d/total\": loss_disc_all, \"learning_rate\": lr, \"grad_norm_d\": grad_norm_d, \"grad_norm_g\": grad_norm_g}\n",
    "        scalar_dict.update({\"loss/g/fm\": loss_fm, \"loss/g/mel\": loss_mel})\n",
    "\n",
    "        scalar_dict.update({\"loss/g/{}\".format(i): v for i, v in enumerate(losses_gen)})\n",
    "        scalar_dict.update({\"loss/d_r/{}\".format(i): v for i, v in enumerate(losses_disc_r)})\n",
    "        scalar_dict.update({\"loss/d_g/{}\".format(i): v for i, v in enumerate(losses_disc_g)})\n",
    "        image_dict = { \n",
    "            \"slice/mel_org\": utils.plot_spectrogram_to_numpy(y_mel[0].data.cpu().numpy()),\n",
    "            \"slice/mel_gen\": utils.plot_spectrogram_to_numpy(y_hat_mel[0].data.cpu().numpy()), \n",
    "            \"all/mel\": utils.plot_spectrogram_to_numpy(mel[0].data.cpu().numpy()),\n",
    "        }\n",
    "        utils.summarize(\n",
    "          writer=writer,\n",
    "          global_step=global_step, \n",
    "          images=image_dict,\n",
    "          scalars=scalar_dict)\n",
    "\n",
    "      if global_step % hps.train.eval_interval == 0:\n",
    "        # evaluate(hps, net_g, eval_loader, writer_eval)\n",
    "        utils.save_checkpoint(net_g, optim_g, hps.train.learning_rate, epoch, os.path.join(hps.model_dir, \"G_{}.pth\".format(global_step)))\n",
    "        utils.save_checkpoint(net_d, optim_d, hps.train.learning_rate, epoch, os.path.join(hps.model_dir, \"D_{}.pth\".format(global_step)))\n",
    "    global_step += 1\n",
    "  \n",
    "  if rank == 0:\n",
    "    logger.info('====> Epoch: {}'.format(epoch))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
